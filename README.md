# Klasifikasi Pesan Spam pada SMS Berbahasa Indonesia Menggunakan IndoBERT

Dikerjakan oleh Tim NLP kelompok 6 - Tubes
Nama Anggota:
### üë• Anggota Tim ‚Äî NLP Kelompok 6

| No | Nama | NIM |
|---:|---|---|
| 1 | **Fajrul Ramadhana Aqsa** | `122140118` |
| 2 | **Nayla Fayyiza Khairina** | `122140033` |
| 3 | **Nasywa Talitha Heryanna** | `122140046` |
| 4 | **Febriani Nawang Wulan Sianipar** | `122140071` |
| 5 | **Zefanya Danovanta Tarigan** | `122140101` |
| 6 | **Giulia Puspo Negoro** | `122140084` |

_Kelompok 6_

## üìã Deskripsi Proyek

Proyek ini mengimplementasikan sistem klasifikasi otomatis untuk mendeteksi pesan spam pada SMS berbahasa Indonesia menggunakan model deep learning **IndoBERT** (Indonesian BERT). Model ini memanfaatkan transfer learning dari pre-trained BERT yang telah dilatih khusus untuk bahasa Indonesia, memberikan pemahaman konteks dan semantik yang lebih baik dibandingkan metode tradisional.

## üéØ Tujuan

- Mengklasifikasikan SMS berbahasa Indonesia ke dalam 2 kategori: **Ham** (pesan legitimate) dan **Spam** (pesan promosi/iklan)
- Memanfaatkan state-of-the-art model IndoBERT untuk Natural Language Processing bahasa Indonesia
- Mencapai akurasi tinggi dalam mendeteksi spam dengan menangani variasi bahasa informal dan slang

## üìä Dataset

**File:** `dataset/dataset_sms_spam_v1.csv`

### Statistik Dataset:
- **Total SMS:** 1,143 pesan
- **Label 0:** 569 pesan Ham (49.78%) - Pesan normal/personal
- **Label 1:** 335 pesan Spam (29.30%) - Penawaran komersial
- **Label 2:** 239 pesan Spam (20.92%) - Promo operator

### Distribusi Setelah Mapping:
- **Ham (0):** 569 pesan (49.78%)
- **Spam (1):** 574 pesan (50.22%)

### Pembagian Data:
- **Training Set:** 800 samples (70%)
- **Validation Set:** 171 samples (15%)
- **Test Set:** 172 samples (15%)

## üèóÔ∏è Arsitektur Model

### Model: IndoBERT
- **Base Model:** `indobenchmark/indobert-base-p1`
- **Type:** BERT-based Transformer untuk klasifikasi sekuens
- **Total Parameters:** 124,647,170 (~125M)
- **Trainable Parameters:** 124,647,170 (100%)

### Hyperparameters:
```python
MAX_LENGTH = 128        # Panjang maksimum sequence tokens
BATCH_SIZE = 16         # Ukuran batch untuk training
EPOCHS = 3              # Jumlah epoch training
LEARNING_RATE = 2e-5    # Learning rate optimizer
```

### Optimizer & Scheduler:
- **Optimizer:** AdamW (Adam with Weight Decay)
- **Scheduler:** Linear Warmup dengan 0 warmup steps
- **Total Training Steps:** 150 steps (50 batches/epoch √ó 3 epochs)

## üîÑ Tahapan Implementasi

### 1. **Import Libraries dan Setup Environment**
   - Import library: PyTorch, Transformers, scikit-learn, pandas, numpy
   - Konfigurasi device (GPU/CPU)
   - Set random seeds untuk reproduktibilitas

### 2. **Load dan Eksplorasi Dataset**
   - Load CSV dataset
   - Analisis distribusi label
   - Cek missing values
   - Visualisasi distribusi data

### 3. **Preprocessing Data**
   - **Rename kolom:** `Teks` ‚Üí `text`, `label` ‚Üí `label`
   - **Label Mapping:** 
     - Label 0 ‚Üí Ham (0)
     - Label 1, 2 ‚Üí Spam (1)
   - **Text Cleaning:**
     - Lowercase
     - Remove URLs
     - Remove extra whitespace
   - Analisis panjang teks dan jumlah kata

### 4. **Load IndoBERT Tokenizer**
   - Load pre-trained tokenizer dari Hugging Face
   - Test tokenization pada sample text
   - Konfigurasi max length dan padding

### 5. **Prepare PyTorch Dataset**
   - Custom `SMSDataset` class untuk handle tokenization
   - Split data: 70% train, 15% validation, 15% test (stratified)
   - Create DataLoader untuk batch processing

### 6. **Initialize Model**
   - Load pre-trained IndoBERT untuk sequence classification
   - Konfigurasi 2 label output (binary classification)
   - Transfer model ke device (GPU/CPU)

### 7. **Setup Training Components**
   - Initialize AdamW optimizer
   - Setup learning rate scheduler dengan linear decay
   - Define training dan evaluation functions

### 8. **Training Model**
   - Training loop selama 3 epochs
   - Monitoring train & validation metrics per epoch
   - Save best model berdasarkan validation accuracy

### 9. **Evaluasi Model**
   - Load best model
   - Evaluate pada test set
   - Generate classification report
   - Create confusion matrix visualization

### 10. **Prediction pada Data Baru**
   - Implementasi fungsi `predict_sms()` untuk inferensi
   - Testing dengan SMS baru
   - Output confidence scores dan probabilitas

### 11. **Save Results**
   - Save model dan tokenizer ke directory
   - Export training history (CSV)
   - Export test results dan predictions
   - Save metrics summary

### 12. **Analisis Error**
   - Identifikasi misclassified messages
   - Analisis pola kesalahan model
   - Generate error report

## üìà Hasil dan Performa Model

### Training History (3 Epochs):

| Epoch | Train Acc | Train Loss | Val Acc | Val Loss |
|-------|-----------|------------|---------|----------|
| 1     | 95.00%    | 0.1918     | 98.25%  | 0.0587   |
| 2     | 98.63%    | 0.0626     | 98.25%  | 0.0615   |
| 3     | 99.25%    | 0.0222     | 98.25%  | 0.0612   |

**Best Validation Accuracy:** 98.25%

### Test Set Performance:

| Metric    | Score   |
|-----------|---------|
| Accuracy  | 97.67%  |
| Precision | 95.56%  |
| Recall    | 100.00% |
| F1-Score  | 97.73%  |

### Confusion Matrix:
```
              Predicted Ham  Predicted Spam
Actual Ham           136              0
Actual Spam            4             32
```

### Per-Class Accuracy:
- **Ham:** 100.00% (136/136)
- **Spam:** 88.89% (32/36)

### Interpretasi Hasil:
- ‚úÖ **Akurasi sangat tinggi (97.67%)** - Model dapat membedakan Ham dan Spam dengan sangat baik
- ‚úÖ **Recall 100%** - Model berhasil mendeteksi SEMUA spam (tidak ada spam yang lolos)
- ‚úÖ **Precision 95.56%** - Sedikit false positive (4 Ham diprediksi sebagai Spam)
- ‚úÖ **F1-Score 97.73%** - Balance yang sangat baik antara precision dan recall

## üß™ Contoh Prediksi

### Test dengan SMS Baru:

| No | SMS | Prediksi | Confidence | Ham Prob | Spam Prob |
|----|-----|----------|------------|----------|-----------|
| 1 | "GRATIS pulsa 100rb!! Buruan klik link ini sekarang juga!" | **Spam** | 99.98% | 0.02% | 99.98% |
| 2 | "Halo, meeting kita jam 2 siang ya di kantor. Jangan lupa bawa dokumen." | **Ham** | 99.89% | 99.89% | 0.11% |
| 3 | "PROMO SPESIAL! Beli 1 GRATIS 1. Hanya hari ini. Hub *123# sekarang!" | **Spam** | 99.99% | 0.01% | 99.99% |
| 4 | "Pak, saya sudah kirim laporan lewat email. Mohon dicek ya." | **Ham** | 99.95% | 99.95% | 0.05% |
| 5 | "Dapatkan BONUS PULSA 50rb dengan isi ulang minimal 10rb. Ketik YA kirim ke 123" | **Spam** | 99.96% | 0.04% | 99.96% |

## üöÄ Cara Menggunakan

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

**Required Libraries:**
- transformers
- torch
- pandas
- numpy
- scikit-learn
- matplotlib
- seaborn
- tqdm

### 2. Jalankan Notebook
```bash
jupyter notebook klasifikasi_spam_sms_indobert.ipynb
```

### 3. Load Trained Model (untuk inferensi)
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Load model dan tokenizer
model = AutoModelForSequenceClassification.from_pretrained('./sms_spam_indobert_model')
tokenizer = AutoTokenizer.from_pretrained('./sms_spam_indobert_model')
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# Predict
def predict_sms(text):
    model.eval()
    encoding = tokenizer.encode_plus(
        text.lower(),
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    with torch.no_grad():
        outputs = model(
            input_ids=encoding['input_ids'].to(device),
            attention_mask=encoding['attention_mask'].to(device)
        )
        probs = torch.softmax(outputs.logits, dim=1)
        pred = torch.argmax(probs, dim=1)
    
    label = 'Ham' if pred.item() == 0 else 'Spam'
    confidence = probs[0][pred.item()].item()
    
    return label, confidence

# Test
text = "GRATIS pulsa 100rb!! Klik link ini sekarang!"
label, conf = predict_sms(text)
print(f"Prediksi: {label} ({conf:.2%})")
```

## üìÅ File Output

Hasil eksekusi notebook menghasilkan file-file berikut:

1. **`best_sms_spam_indobert.pt`** - Model weights terbaik (state_dict)
2. **`sms_spam_indobert_model/`** - Directory berisi model dan tokenizer lengkap
   - `config.json`
   - `model.safetensors`
   - `tokenizer.json`
   - `vocab.txt`
   - dll.
3. **`training_history_sms_spam.csv`** - History metrics per epoch
4. **`test_results_sms_spam.csv`** - Hasil prediksi pada test set
5. **`metrics_summary_sms_spam.csv`** - Summary metrik evaluasi
6. **`training_history_sms_spam.png`** - Plot training curves
7. **`confusion_matrix_sms_spam.png`** - Visualisasi confusion matrix

## üî¨ Analisis Error

### Misclassified Messages:
- **Total Error:** 4 dari 172 samples (2.33%)
- **False Positive (Ham ‚Üí Spam):** 4 pesan
- **False Negative (Spam ‚Üí Ham):** 0 pesan

### Pola Kesalahan:
Model cenderung lebih "hati-hati" dengan memprediksi beberapa Ham sebagai Spam (conservative approach), namun **tidak pernah melewatkan spam** (recall 100%). Ini adalah perilaku yang baik untuk aplikasi spam filter.

## ‚ú® Keunggulan Metode IndoBERT

1. ‚úÖ **Pre-trained khusus Bahasa Indonesia** - Memahami struktur dan konteks bahasa Indonesia
2. ‚úÖ **Transfer Learning** - Memanfaatkan pengetahuan dari corpus besar
3. ‚úÖ **Contextual Understanding** - BERT memahami konteks kalimat secara bidirectional
4. ‚úÖ **Tidak perlu Feature Engineering manual** - Model belajar representasi otomatis
5. ‚úÖ **Robust terhadap variasi bahasa** - Dapat menangani bahasa informal, slang, dan typo
6. ‚úÖ **State-of-the-art Performance** - Akurasi 97.67% pada test set

## üéØ Aplikasi Praktis

1. **Filter SMS Spam** - Otomatis memfilter pesan spam di aplikasi messaging
2. **Deteksi Phishing** - Identifikasi pesan penipuan dan phishing
3. **Content Moderation** - Moderasi konten di platform komunikasi
4. **Marketing Analysis** - Analisis kampanye marketing dan promo
5. **Customer Service** - Prioritisasi pesan pelanggan (urgent vs promo)

## üîÆ Saran Pengembangan

1. **Augmentasi Data** - Tambah dataset training untuk meningkatkan generalisasi
2. **Hyperparameter Tuning** - Grid search untuk optimal hyperparameters
3. **Ensemble Methods** - Kombinasi dengan model lain (SVM, Random Forest, dll)
4. **Multi-class Classification** - Klasifikasi kategori spam lebih spesifik (promo, penipuan, phishing, dll)
5. **API Deployment** - Deploy sebagai REST API untuk real-time prediction
6. **Mobile Integration** - Integrasi ke aplikasi mobile SMS
7. **Continuous Learning** - Update model secara berkala dengan data baru

## üìö Referensi

- **IndoBERT Paper:** [IndoBERT: A Pre-trained Language Model for Indonesian](https://arxiv.org/abs/2011.00677)
- **Hugging Face Transformers:** [https://huggingface.co/transformers/](https://huggingface.co/transformers/)
- **IndoBERT Model:** [https://huggingface.co/indobenchmark/indobert-base-p1](https://huggingface.co/indobenchmark/indobert-base-p1)
- **BERT Paper:** [Attention is All You Need](https://arxiv.org/abs/1706.03762)



**Status:** ‚úÖ **Model Trained & Evaluated Successfully**  
**Last Updated:** November 6, 2025  
**Notebook:** `klasifikasi_spam_sms_indobert.ipynb`
